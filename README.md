
<div align="center">
<img src="head.png" >
</div>

<h1 align="center">EVA 4.0 (Extensive Vision AI)</h1>

This contains the solutions to the assignments given in The School of AI - Extensive Vision AI 4.0

## Website: [https://satyajitghana.github.io/TSAI-DeepVision-EVA4.0/](https://satyajitghana.github.io/TSAI-DeepVision-EVA4.0/)
`[i'd prefer to use the website link]`

---

1. [Python Basics](01_PythonBasics/Assignment.html)

    This describes the very basics of Python, i would recommend binge watching Raymond Hettinger's YouTube Videos, as much as you can, also learn list comprehension, slicing, partial, functools, functional programming, classes, MRO, decorators, lambdas, python 3 typing
    
    Also here i learnt the basics of how a Neural Network learns, how the different channels are formed, what are kernels, how does the DNN make sense of the input it gets, and more !
    
    Have you ever wondered, like why do we only use 3x3 kernels ? i had always wondered, why not 5x5 ? 7x7 ? in this session i learnt why, and how does even the kernel size matter ? why is it only odd numbers ? and why only squares ? and why is 3x3 kernel used twice same as a 5x5 kernel, what is receptive field ?

2. [Neural Architecture](02_NeuralArchitecture/README.md)

    This describes the basic neural network architecure, see its page for details

3. [PyTorch 101](03_PyTorch101/README.md)

    Basic Pytorch architecture for working with neural networks, introduces you to `nn.Module`, optimizers, forward and backward pass, datasets, how to apply simple augmentation.

4. [Architecture Basics](04_ArchitectureBasics/README.md)

    Here we had to train MNIST to get 99.4% accuracy with some given contraints, was quite fun to do this, got me out of the noob shell of what a neural network actually is and what it does, because i had to write code manually, not copy paste any more.

5. [Coding Drill](05_CodingDrill/README.md)

    This was very important to realise the basic steps required to make a neural network and then go on to optimize it, to get the perfect model size and accuracy, very important, please see its documentation, and all the notebooks

6. [Normalization Regularization](06_NormalizationRegularization/index.html)

    This assigment focuses on the importance of normalization and regularization in neural networks, aim was to also get > 99.4% accuracy in less than 40 epochs for MNIST with limited model parameters

7. [Advanced Convolution](07_AdvancedConvolution/README.md)

    Here i was introduced to various convolution types you can add in the network, we were given a custom network which we had to implement, also we had to make a custom library of python to support and ease the process of NN building and training, this was quite a eye openener for me, i made my first python package !, also i learnt the value of time contraints, since we have to finish the assignments within a week, along with my college work it was burdening, or maybe i was procrastinating?

8. [Advanced Architecture](08_AdvancedArchitecture/README.html)

    Here i was introduced to ResNet18 and CIFAR dataset with aim to get 85% test accuracy

9. [Model Diagnostics](09_ModelDiagnostics/README.html)

    This was amazing, i was introduced to GradCAM, and i myself learnt about saliency map, this was something i also used in my college group project, it's used to diagnosing if the model is actually learning anything from the dataset. Quite a nifty feature, eh ?

10. [Advanced Training](10_AdvancedTraining/README.html)

    Here i had to use LR Finder to find the best learning rate for the model, i also used OneCyclePolicy for faster convergence. i reached 92.03% accuracy in CIFAR using ResNet18

11. [Super Convergence](11_SuperConvergence/index.html)

    A custom architecture was implemented here, along with that i used OneCycleLR to improve the convergence of the NN

12. [Tiny Image Net](12_TinyImageNet/index.html)

    Here we had to do image annotation and collect doggo dataset.

    Also i had to make a custom dataloader and dataset class in PyTorch to support TinyImageNet, and then train a model to reach 60% accuracy, which i failed to, but still i learnt from my mistakes ! the one who doesnt make mistakes does really make anything does he ?

13. [YOLOV3](13_YoloV3/index.html)

    I was introduced to YOLO, something i always wondered how it exactly worked, and why is it called YOLO ? now i understand why. and people complain about the FPS of YOLO, now i know why, they dont pay attention to the anchor boxes, which is very important and its different for different datasets.

    I made a custom Bugs Bunny detector using the YOLO architecture :) i like my detector :) i like bugs bunny :) i custom collected bugs bunny images, self annotated about 600 images of my bunny and trained the network for like 5 hours on a Tesla P100

14. [RCNN](14_RCNN/index.html)

    I was introduced to RCNN family and SSD, but that wasnt the main thing here.

    The main thing was that i created a dataset containing 1.2M images ! do you understand how crazy that is ? this was a pre-req for the upcoming CapStone project which will be to do object segmentation and also monocular depth estimation both at the same time.

15. [CapStone Project](15_CapstoneProject/README.md)

    This was the final project, please see its README, i spent a lot of time writing code and documenting it.

    I'm sure you'll be impressed by this one ;)

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=satyajitghana/TSAI-DeepVision-EVA4.0&type=Date)](https://star-history.com/#satyajitghana/TSAI-DeepVision-EVA4.0&Date)

---
<h3 align="center">Made with ðŸ’˜ by shadowleaf</h3>
